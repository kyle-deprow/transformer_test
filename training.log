2023-09-25 18:04:49,111:INFO: Training RNN [150 150]
2023-09-25 18:04:55,413:INFO: iter 0, loss: 4.357379358256622, test_loss 3.87218941414105
2023-09-25 18:05:58,112:INFO: iter 250, loss: 2.337645969095514, test_loss 2.010025051916701
2023-09-25 18:07:03,877:INFO: iter 500, loss: 1.9144061216681756, test_loss 1.8258939556435017
2023-09-25 18:08:22,701:INFO: iter 750, loss: 1.7635199800265156, test_loss 1.6974780443509085
2023-09-25 18:09:30,500:INFO: iter 1000, loss: 1.6306768101439757, test_loss 1.6346440188374574
2023-09-25 18:14:28,502:INFO: iter 2000, loss: 1.4691834090890934, test_loss 1.5075091760432084
2023-09-25 18:19:46,001:INFO: iter 3000, loss: 1.3925010150054857, test_loss 1.4410967287539116
2023-09-25 18:25:06,106:INFO: iter 4000, loss: 1.3561625709239817, test_loss 1.407142505840058
2023-09-25 18:28:37,522:INFO: iter 5000, loss: 1.3321542652458147, test_loss 1.3923120075091096
2023-09-25 18:32:10,073:INFO: iter 6000, loss: 1.3201342874268411, test_loss 1.3767019253065524
2023-09-25 18:36:29,484:INFO: iter 7000, loss: 1.3108504900395952, test_loss 1.365215811066083
2023-09-25 18:40:21,294:INFO: iter 8000, loss: 1.3059618626015006, test_loss 1.35100159517457
2023-09-25 18:44:08,105:INFO: iter 9000, loss: 1.299345329222351, test_loss 1.3418552554690901
2023-09-25 18:47:48,285:INFO: iter 10000, loss: 1.2924102287733614, test_loss 1.338498293286221
2023-09-25 19:26:22,982:INFO: iter 20000, loss: 1.2504092054198457, test_loss 1.3185047489883606
2023-09-25 20:03:52,399:INFO: iter 30000, loss: 1.228146693472435, test_loss 1.313246701582675
2023-09-25 21:27:09,232:INFO: iter 50000, loss: 1.1833271747456187, test_loss 1.3064675463797495
2023-09-25 23:58:15,846:INFO: iter 75000, loss: 1.1251881380276971, test_loss 1.3099112418423453
2023-09-26 00:05:13,338:INFO: iter 76500, loss: 1.1729730637672524, test_loss 1.3029169478490596



2023-09-26 01:54:27,119:INFO: Training RNN [250, 250] + new 'sanderson.txt':
2023-09-26 01:54:40,076:INFO: iter 0, loss: 4.3575632250554905, test_loss 4.113624969513882
2023-09-26 01:55:34,756:INFO: iter 250, loss: 2.2939420457531483, test_loss 1.99062217393774
2023-09-26 01:56:25,904:INFO: iter 500, loss: 1.8757391343451026, test_loss 1.80588265283011
2023-09-26 01:57:17,169:INFO: iter 750, loss: 1.71346883590214, test_loss 1.7085790352306036
2023-09-26 01:58:09,622:INFO: iter 1000, loss: 1.5816158249586665, test_loss 1.6419921854752761
2023-09-26 02:01:34,873:INFO: iter 2000, loss: 1.4701710449726977, test_loss 1.4790495454316954
2023-09-26 02:05:00,359:INFO: iter 3000, loss: 1.3869977685325758, test_loss 1.443122701938415
2023-09-26 02:08:24,419:INFO: iter 4000, loss: 1.384070344323753, test_loss 1.3949518225732311
2023-09-26 02:11:52,904:INFO: iter 5000, loss: 1.3438685966299864, test_loss 1.3807236523826123
2023-09-26 02:29:48,373:INFO: iter 10000, loss: 1.2782969386885437, test_loss 1.3286307969126363
2023-09-26 03:07:07,055:INFO: iter 20000, loss: 1.258442352913596, test_loss 1.295995659196987
2023-09-26 03:43:42,173:INFO: iter 30000, loss: 1.225569974392955, test_loss 1.2932380749022856
2023-09-26 04:57:15,364:INFO: iter 50000, loss: 1.2515353215745992, test_loss 1.2853750365224863
2023-09-26 06:29:06,025:INFO: iter 75000, loss: 1.2406037333282183, test_loss 1.2818011467063857
2023-09-26 07:41:24,972:INFO: iter 93500, loss: 1.216671928648229, test_loss 1.267197975564648


2023-09-26 07:54:05,140:INFO: Training RNN [200 200]:
2023-09-26 07:54:11,236:INFO: iter 0, loss: 4.357377477345979, test_loss 4.326771262622518
2023-09-26 07:56:41,937:INFO: iter 1000, loss: 1.6318979572441867, test_loss 1.6787645859429399
2023-09-26 07:59:11,168:INFO: iter 2000, loss: 1.518754248971079, test_loss 1.5228933819259334
2023-09-26 08:07:17,002:INFO: iter 5000, loss: 1.3754957081608312, test_loss 1.4140501035954716
2023-09-26 08:20:40,413:INFO: iter 10000, loss: 1.3295748639108604, test_loss 1.3778760360017235
2023-09-26 08:46:01,160:INFO: iter 20000, loss: 1.2738913896205006, test_loss 1.3263286505631862
2023-09-26 09:11:48,625:INFO: iter 30000, loss: 1.249903733427912, test_loss 1.3201579615142736
2023-09-26 10:04:29,673:INFO: iter 50000, loss: 1.246930529991181, test_loss 1.3043402779969735
2023-09-26 11:08:34,437:INFO: iter 75000, loss: 1.251086225406, test_loss 1.295441418696581



2023-09-26 13:55:37,913:INFO: Training RNN [250, 250] + h_init param:
2023-09-26 13:59:01,568:INFO: iter 0, loss: 4.357040223731806, test_loss 4.069574052925316
2023-09-26 14:00:58,346:INFO: iter 250, loss: 2.285021327108137, test_loss 2.000046664617254
2023-09-26 14:02:04,004:INFO: iter 500, loss: 1.8656114735729297, test_loss 1.8263050939863958
2023-09-26 14:03:14,396:INFO: iter 750, loss: 1.7110213888734287, test_loss 1.7240889766601257
2023-09-26 14:04:20,296:INFO: iter 1000, loss: 1.5611805691507068, test_loss 1.6537617045216964
2023-09-26 14:09:48,776:INFO: iter 2000, loss: 1.4725917204512453, test_loss 1.495353874970223
2023-09-26 14:13:16,569:INFO: iter 3000, loss: 1.4030849869376771, test_loss 1.44874664999262
2023-09-26 14:20:36,719:INFO: iter 5000, loss: 1.3478760114228507, test_loss 1.387431191178374
2023-09-26 14:38:03,260:INFO: iter 10000, loss: 1.30239978300101, test_loss 1.3340800512268969
2023-09-26 16:02:15,762:INFO: iter 30000, loss: 1.2489317411962768, test_loss 1.3060405968862538
2023-09-26 17:32:37,635:INFO: iter 50000, loss: 1.238764623478701, test_loss 1.2968074119393596
2023-09-26 19:53:02,932:INFO: iter 75000, loss: 1.2193543677768566, test_loss 1.2810967882905262
2023-09-26 20:36:55,458:INFO: iter 83750, loss: 1.2176052244643596, test_loss 1.2829442757655822


2023-09-26 20:44:04,302:INFO: Training RNN [250 250] timesteps = 200
2023-09-26 20:44:17,245:INFO: iter 0, loss: 4.357716133636559, test_loss 4.247600515342754
2023-09-26 20:46:30,272:INFO: iter 250, loss: 2.226056430552114, test_loss 1.894383125049748
2023-09-26 20:49:10,858:INFO: iter 500, loss: 1.7365407450423864, test_loss 1.7044575476892194
2023-09-26 20:51:33,628:INFO: iter 750, loss: 1.6275453097784163, test_loss 1.5939373179983352
2023-09-26 20:53:41,421:INFO: iter 1000, loss: 1.5464133399502766, test_loss 1.5269574932403853
2023-09-26 21:02:21,394:INFO: iter 2000, loss: 1.4069875481621343, test_loss 1.4145170662349917
2023-09-26 21:10:42,235:INFO: iter 3000, loss: 1.3366559807884189, test_loss 1.3580600933446827
2023-09-26 21:18:36,128:INFO: iter 4000, loss: 1.3163101525409604, test_loss 1.3322057579057753
2023-09-26 21:26:07,114:INFO: iter 5000, loss: 1.2924833903174693, test_loss 1.3374357080949795
2023-09-26 22:02:05,121:INFO: iter 10000, loss: 1.2321497222880413, test_loss 1.265014537798303
2023-09-27 00:26:13,505:INFO: iter 30000, loss: 1.175715160248953, test_loss 1.2606329750780783
2023-09-27 02:44:27,956:INFO: iter 50000, loss: 1.1857337882678936, test_loss 1.2460070429612735
2023-09-27 05:39:33,908:INFO: iter 75000, loss: 1.148399945659407, test_loss 1.2482125118380867
2023-09-27 07:57:55,088:INFO: iter 94750, loss: 1.1562477026281304, test_loss 1.2359778561576187


2023-09-27 08:53:17,309:INFO: Training RNN [250 250], lower()
2023-09-27 08:53:25,028:INFO: iter 0, loss: 3.952226923569765, test_loss 3.646841513510745
2023-09-27 08:54:59,220:INFO: iter 250, loss: 2.09305798893156, test_loss 1.80049133358682
2023-09-27 08:56:32,423:INFO: iter 500, loss: 1.6624038189148713, test_loss 1.6183578540533667
2023-09-27 08:58:12,567:INFO: iter 750, loss: 1.5554896307789081, test_loss 1.5305379966633696
2023-09-27 08:59:53,478:INFO: iter 1000, loss: 1.4766430396699768, test_loss 1.4656147724685629
2023-09-27 09:25:57,504:INFO: iter 5000, loss: 1.2688533645822646, test_loss 1.3001007172963015
2023-09-27 10:00:13,579:INFO: iter 10000, loss: 1.207108439810635, test_loss 1.2517164123541147


2023-09-27 10:20:09,413:INFO: Training RNN [250 250 250]
2023-09-27 10:20:20,906:INFO: iter 0, loss: 4.357576163244516, test_loss 3.971627246719618
2023-09-27 10:23:19,854:INFO: iter 250, loss: 2.190924585301957, test_loss 1.8284691970657818
2023-09-27 10:26:24,313:INFO: iter 500, loss: 1.675085818364916, test_loss 1.6305244210745549
2023-09-27 10:29:39,933:INFO: iter 750, loss: 1.5712949271219334, test_loss 1.526645418919715
2023-09-27 10:32:38,550:INFO: iter 1000, loss: 1.4881128933248227, test_loss 1.4692293179678033
2023-09-27 10:45:14,102:INFO: iter 2000, loss: 1.3515744260312488, test_loss 1.3772980816375453
2023-09-27 10:58:27,870:INFO: iter 3000, loss: 1.319832883641237, test_loss 1.328945390241877
2023-09-27 11:11:13,493:INFO: iter 4000, loss: 1.2730110890559223, test_loss 1.292352601232823
2023-09-27 11:23:44,375:INFO: iter 5000, loss: 1.2590695711236066, test_loss 1.2941244732083552
2023-09-27 11:35:53,840:INFO: iter 6000, loss: 1.2409803230440877, test_loss 1.2658629753745096
2023-09-27 11:48:31,968:INFO: iter 7000, loss: 1.2242141384225562, test_loss 1.2662348351128858
2023-09-27 12:00:07,776:INFO: iter 8000, loss: 1.2265287596029828, test_loss 1.2626032534617342
2023-09-27 12:12:16,003:INFO: iter 9000, loss: 1.1989151060902, test_loss 1.2447745706419209
2023-09-27 12:24:15,203:INFO: iter 10000, loss: 1.1857447003150974, test_loss 1.2494824456281257

2023-09-27 12:34:34,497:INFO: Training LSTM [250 250]
2023-09-27 12:35:06,971:INFO: iter 0, loss: 4.356709288872118, test_loss 4.3378998541350295
2023-09-27 12:43:35,774:INFO: iter 250, loss: 2.5168688028081756, test_loss 2.2027347004105176
2023-09-27 12:52:09,926:INFO: iter 500, loss: 2.0208947407162627, test_loss 1.9446963627284513
2023-09-27 13:00:20,280:INFO: iter 750, loss: 1.838722386898187, test_loss 1.790432313520965
2023-09-27 13:08:38,095:INFO: iter 1000, loss: 1.6978532112750375, test_loss 1.6773174131133648
2023-09-27 13:42:12,792:INFO: iter 2000, loss: 1.4453136650745169, test_loss 1.4508850913246538
2023-09-27 14:27:52,056:INFO: iter 3000, loss: 1.3318492244015478, test_loss 1.3600069035215943
2023-09-27 15:11:34,177:INFO: iter 4000, loss: 1.2872107399860602, test_loss 1.2991297899207392
2023-09-27 16:05:09,572:INFO: iter 5000, loss: 1.2477490801396642, test_loss 1.2747476347895614
2023-09-27 16:50:13,560:INFO: iter 6000, loss: 1.2124133761863616, test_loss 1.2362211991117893
2023-09-27 17:23:04,807:INFO: iter 7000, loss: 1.19820305881659, test_loss 1.2258163437238105
2023-09-27 19:38:28,013:INFO: iter 8000, loss: 1.1746406409149472, test_loss 1.2133527927670837
2023-09-27 20:35:34,333:INFO: iter 9000, loss: 1.1629738315404605, test_loss 1.2009230328987697
2023-09-27 21:25:25,355:INFO: iter 10000, loss: 1.1477197924618279, test_loss 1.1875520650930693
2023-09-28 03:28:49,460:INFO: iter 20000, loss: 1.0813988392832792, test_loss 1.1580898952673133
2023-09-28 08:55:00,693:INFO: iter 30000, loss: 1.0383186175094308, test_loss 1.1542107244966184
2023-09-28 14:04:17,958:INFO: iter 39000, loss: 1.0291704285437973, test_loss 1.1466805409317984


2023-09-28 21:25:50,200:INFO: Training LSTM [250 250 250] + 500 timesteps
2023-09-28 21:26:32,405:INFO: iter 0, loss: 4.356728506352806, test_loss 4.340685428344342
2023-09-29 01:43:32,943:INFO: iter 1000, loss: 1.6550966366956115, test_loss 1.5851789450408411
2023-09-29 04:19:37,205:INFO: iter 2000, loss: 1.3735257619837238, test_loss 1.3445387195956104
2023-09-29 06:56:23,209:INFO: iter 3000, loss: 1.2748879784671208, test_loss 1.2561665948748086
2023-09-29 09:36:31,938:INFO: iter 4000, loss: 1.1979135459580268, test_loss 1.2003116337463864
2023-09-29 13:57:37,111:INFO: iter 5000, loss: 1.1644717150563304, test_loss 1.1706972676447407
2023-09-29 16:38:06,810:INFO: iter 6000, loss: 1.1420186065379943, test_loss 1.1583029982276993
2023-09-29 19:16:09,510:INFO: iter 7000, loss: 1.1087430796998077, test_loss 1.1474372475016215
2023-09-30 00:21:41,939:INFO: iter 8000, loss: 1.1059763055323442, test_loss 1.1422335130679864
2023-09-30 03:38:50,968:INFO: iter 9000, loss: 1.0960028040689394, test_loss 1.129390417130345
2023-09-30 06:23:29,782:INFO: iter 10000, loss: 1.0765880507999213, test_loss 1.1315080043640187
2023-09-30 09:06:07,558:INFO: iter 11000, loss: 1.067482994764421, test_loss 1.1266452444467079
2023-09-30 11:55:43,523:INFO: iter 12000, loss: 1.0629233858248706, test_loss 1.1268050772144678
2023-09-30 14:05:48,413:INFO: iter 12750, loss: 1.0606487350294342, test_loss 1.1269636814664457

2023-10-03 12:17:33,111:INFO: Training LSTM [250]
2023-10-03 12:17:45,758:INFO: iter 0, loss: 4.356717440557288, test_loss 4.338019432371997
2023-10-03 12:24:19,445:INFO: iter 250, loss: 2.4067302558351975, test_loss 2.096301656533079
2023-10-03 12:32:21,082:INFO: iter 500, loss: 1.9855081623931745, test_loss 1.8854350771012907
2023-10-03 12:38:04,552:INFO: iter 750, loss: 1.818913332752486, test_loss 1.7565702983311766
2023-10-03 12:43:35,218:INFO: iter 1000, loss: 1.6940006072171525, test_loss 1.669960203409748
2023-10-03 12:49:36,818:INFO: iter 1250, loss: 1.6230400327741548, test_loss 1.5930878538017124
2023-10-03 12:55:16,171:INFO: iter 1500, loss: 1.5679227934269016, test_loss 1.5435827179193868
2023-10-03 13:00:59,897:INFO: iter 1750, loss: 1.485371151960811, test_loss 1.5048830755251983
2023-10-03 13:07:37,284:INFO: iter 2000, loss: 1.4810884215351405, test_loss 1.479516157794274
2023-10-03 13:30:34,222:INFO: iter 3000, loss: 1.3839192552264892, test_loss 1.376892379364667
2023-10-03 13:57:19,498:INFO: iter 4000, loss: 1.3125002661834206, test_loss 1.3183643842021384
2023-10-03 14:41:54,370:INFO: iter 5000, loss: 1.2891275098731458, test_loss 1.285431859415257
2023-10-03 15:39:27,171:INFO: iter 6000, loss: 1.2379010902339793, test_loss 1.2630252895439045
2023-10-03 17:06:00,869:INFO: iter 6750, loss: 1.2311108733593001, test_loss 1.2441777550213775


2023-10-03 20:51:36,177:INFO: Training DeepMemoryLSTM [250]
2023-10-03 20:52:14,842:INFO: iter 0, loss: 4.35721953491485, test_loss 4.458182323845401
2023-10-03 21:02:33,514:INFO: iter 250, loss: 2.5671029933710727, test_loss 2.1690128497914407
2023-10-03 21:12:42,467:INFO: iter 500, loss: 2.049729160449494, test_loss 2.024094418853535
2023-10-03 21:23:34,227:INFO: iter 750, loss: 2.008025045822429, test_loss 1.9045617399301769
2023-10-03 21:34:43,744:INFO: iter 1000, loss: 1.8314730617117725, test_loss 1.8542330135330887
2023-10-03 21:45:44,672:INFO: iter 1250, loss: 1.8928676591427203, test_loss 1.8685297084289039
2023-10-03 21:55:47,274:INFO: iter 1500, loss: 1.8498111022358175, test_loss 1.8310992744803043
2023-10-03 22:06:16,746:INFO: iter 1750, loss: 1.869079823892054, test_loss 1.961025793633084
2023-10-03 22:17:03,883:INFO: iter 2000, loss: 1.9743764437031006, test_loss 1.970770598705255


2023-11-13 22:46:07,192:INFO: Training RNN [250 250] 200 steps torch cpu

2023-11-13 22:49:39,520:INFO: Loading text inputs...
2023-11-13 22:49:39,597:INFO: Training
2023-11-13 22:49:43,154:INFO: iter 0, loss: 4.35713529586792, test_loss 4.330650329589844
2023-11-14 00:28:45,295:INFO: Loading text inputs...
2023-11-14 00:28:45,377:INFO: Training
2023-11-14 00:29:06,237:INFO: Loading text inputs...
2023-11-14 00:29:06,323:INFO: Training
2023-11-14 00:29:08,093:INFO: iter 0, loss: 4.357841968536377, test_loss 4.32282018661499
2023-11-14 00:29:40,898:INFO: Loading text inputs...
2023-11-14 00:29:40,989:INFO: Training
2023-11-14 00:29:45,628:INFO: iter 0, loss: 4.356992721557617, test_loss 3.842986583709717
2023-11-14 00:29:51,024:INFO: Loading text inputs...
2023-11-14 00:29:51,121:INFO: Training
2023-11-14 00:29:53,206:INFO: iter 0, loss: 4.3577070236206055, test_loss 4.16045618057251
2023-11-14 00:31:08,772:INFO: iter 500, loss: 1.6572866439819336, test_loss 1.669069528579712
2023-11-14 00:32:24,610:INFO: iter 1000, loss: 1.5034966468811035, test_loss 1.5204923152923584
2023-11-14 00:33:40,449:INFO: iter 1500, loss: 1.413607120513916, test_loss 1.446782112121582
2023-11-14 00:34:54,937:INFO: iter 2000, loss: 1.3950223922729492, test_loss 1.4112296104431152
2023-11-14 00:36:08,834:INFO: iter 2500, loss: 1.3599371910095215, test_loss 1.3627055883407593
2023-11-14 00:37:22,967:INFO: iter 3000, loss: 1.3303040266036987, test_loss 1.3438011407852173
2023-11-14 00:38:36,981:INFO: iter 3500, loss: 1.3277738094329834, test_loss 1.3459948301315308
2023-11-14 00:39:51,031:INFO: iter 4000, loss: 1.3006033897399902, test_loss 1.3097419738769531
2023-11-14 00:41:05,015:INFO: iter 4500, loss: 1.2921884059906006, test_loss 1.3161842823028564
2023-11-14 00:42:22,280:INFO: iter 5000, loss: 1.284257411956787, test_loss 1.303209662437439
2023-11-14 00:43:38,857:INFO: iter 5500, loss: 1.2833784818649292, test_loss 1.3006443977355957
2023-11-14 00:44:55,745:INFO: iter 6000, loss: 1.252090334892273, test_loss 1.2883516550064087
2023-11-14 00:46:10,563:INFO: iter 6500, loss: 1.2461256980895996, test_loss 1.286557912826538
2023-11-14 00:47:25,001:INFO: iter 7000, loss: 1.2280415296554565, test_loss 1.3027830123901367
2023-11-14 00:48:38,964:INFO: iter 7500, loss: 1.2428309917449951, test_loss 1.2765417098999023
2023-11-14 00:49:54,373:INFO: iter 8000, loss: 1.2394847869873047, test_loss 1.2763245105743408
2023-11-14 00:51:08,308:INFO: iter 8500, loss: 1.251642107963562, test_loss 1.2882827520370483
2023-11-14 00:52:22,486:INFO: iter 9000, loss: 1.2444336414337158, test_loss 1.2618966102600098
2023-11-14 00:53:37,898:INFO: iter 9500, loss: 1.2362812757492065, test_loss 1.2621668577194214
2023-11-14 00:54:53,123:INFO: iter 10000, loss: 1.2389897108078003, test_loss 1.264438509941101
2023-11-14 00:56:07,252:INFO: iter 10500, loss: 1.2287683486938477, test_loss 1.2524584531784058
2023-11-14 00:57:21,088:INFO: iter 11000, loss: 1.2316837310791016, test_loss 1.2649537324905396
2023-11-14 00:58:35,260:INFO: iter 11500, loss: 1.2273279428482056, test_loss 1.2574809789657593
2023-11-14 00:59:49,408:INFO: iter 12000, loss: 1.2288446426391602, test_loss 1.2620528936386108
2023-11-14 01:01:02,451:INFO: iter 12500, loss: 1.205696940422058, test_loss 1.2510592937469482
2023-11-14 01:02:16,416:INFO: iter 13000, loss: 1.202749490737915, test_loss 1.2650715112686157
2023-11-14 01:03:30,578:INFO: iter 13500, loss: 1.1920312643051147, test_loss 1.2581948041915894
2023-11-14 01:04:44,706:INFO: iter 14000, loss: 1.2048102617263794, test_loss 1.2580286264419556
2023-11-14 01:05:58,559:INFO: iter 14500, loss: 1.2075079679489136, test_loss 1.2477569580078125
2023-11-14 01:07:13,182:INFO: iter 15000, loss: 1.2151570320129395, test_loss 1.2705382108688354
2023-11-14 01:08:27,299:INFO: iter 15500, loss: 1.2147458791732788, test_loss 1.2403907775878906
2023-11-14 01:09:42,042:INFO: iter 16000, loss: 1.2085590362548828, test_loss 1.2423230409622192
2023-11-14 01:10:56,931:INFO: iter 16500, loss: 1.203382134437561, test_loss 1.2414984703063965
2023-11-14 01:12:12,143:INFO: iter 17000, loss: 1.2009410858154297, test_loss 1.2352675199508667
2023-11-14 01:13:26,642:INFO: iter 17500, loss: 1.2060385942459106, test_loss 1.2399091720581055
2023-11-14 01:14:41,697:INFO: iter 18000, loss: 1.2041126489639282, test_loss 1.2539952993392944
2023-11-14 01:15:55,928:INFO: iter 18500, loss: 1.2055310010910034, test_loss 1.2516376972198486
2023-11-14 01:17:10,775:INFO: iter 19000, loss: 1.1830885410308838, test_loss 1.237382173538208
2023-11-14 01:18:26,249:INFO: iter 19500, loss: 1.1892997026443481, test_loss 1.2409451007843018
2023-11-14 01:19:41,072:INFO: iter 20000, loss: 1.1781189441680908, test_loss 1.2326843738555908
2023-11-14 01:20:55,699:INFO: iter 20500, loss: 1.1842334270477295, test_loss 1.2416268587112427
2023-11-14 01:22:09,688:INFO: iter 21000, loss: 1.1874167919158936, test_loss 1.2338573932647705
2023-11-14 01:23:23,745:INFO: iter 21500, loss: 1.1931116580963135, test_loss 1.2433165311813354
2023-11-14 01:24:38,101:INFO: iter 22000, loss: 1.1985609531402588, test_loss 1.229792833328247
2023-11-14 01:25:52,150:INFO: iter 22500, loss: 1.1927424669265747, test_loss 1.2326687574386597
2023-11-14 01:27:06,681:INFO: iter 23000, loss: 1.1874638795852661, test_loss 1.234374761581421
2023-11-14 01:28:20,617:INFO: iter 23500, loss: 1.1809096336364746, test_loss 1.2246320247650146
2023-11-14 01:29:35,103:INFO: iter 24000, loss: 1.1901499032974243, test_loss 1.227087140083313
2023-11-14 01:30:49,712:INFO: iter 24500, loss: 1.186461091041565, test_loss 1.2362217903137207
2023-11-14 01:32:03,997:INFO: iter 25000, loss: 1.1908159255981445, test_loss 1.2342591285705566
2023-11-14 01:33:17,964:INFO: iter 25500, loss: 1.1646907329559326, test_loss 1.2354941368103027
2023-11-14 01:34:32,300:INFO: iter 26000, loss: 1.1749155521392822, test_loss 1.2309163808822632
2023-11-14 01:35:46,332:INFO: iter 26500, loss: 1.1671561002731323, test_loss 1.228615641593933
2023-11-14 01:37:00,614:INFO: iter 27000, loss: 1.176143765449524, test_loss 1.228853702545166
2023-11-14 01:38:15,508:INFO: iter 27500, loss: 1.1775095462799072, test_loss 1.2264721393585205
2023-11-14 01:39:34,109:INFO: iter 28000, loss: 1.1716586351394653, test_loss 1.2362502813339233
2023-11-14 01:40:53,797:INFO: iter 28500, loss: 1.1873072385787964, test_loss 1.225264310836792
2023-11-14 01:42:12,980:INFO: iter 29000, loss: 1.1767549514770508, test_loss 1.2196273803710938
2023-11-14 01:43:31,856:INFO: iter 29500, loss: 1.175933599472046, test_loss 1.222093939781189
2023-11-14 01:44:50,067:INFO: iter 30000, loss: 1.171156883239746, test_loss 1.220808982849121
2023-11-14 01:46:07,314:INFO: iter 30500, loss: 1.1817638874053955, test_loss 1.223780870437622
2023-11-14 01:47:25,645:INFO: iter 31000, loss: 1.1684021949768066, test_loss 1.2239885330200195
2023-11-14 01:48:42,742:INFO: iter 31500, loss: 1.175971508026123, test_loss 1.2351466417312622
2023-11-14 01:49:59,515:INFO: iter 32000, loss: 1.1477630138397217, test_loss 1.2241425514221191
2023-11-14 01:51:14,824:INFO: iter 32500, loss: 1.164919376373291, test_loss 1.220766544342041
2023-11-14 01:52:29,712:INFO: iter 33000, loss: 1.158949851989746, test_loss 1.2153533697128296
2023-11-14 01:53:43,835:INFO: iter 33500, loss: 1.1665352582931519, test_loss 1.2193305492401123
2023-11-14 01:54:57,973:INFO: iter 34000, loss: 1.16741943359375, test_loss 1.214692234992981
2023-11-14 01:56:11,913:INFO: iter 34500, loss: 1.1648821830749512, test_loss 1.2192466259002686
2023-11-14 01:57:26,051:INFO: iter 35000, loss: 1.174464225769043, test_loss 1.214679479598999
2023-11-14 01:58:40,164:INFO: iter 35500, loss: 1.164723515510559, test_loss 1.2149544954299927
2023-11-14 01:59:53,671:INFO: iter 36000, loss: 1.1654587984085083, test_loss 1.2156989574432373
2023-11-14 02:01:06,892:INFO: iter 36500, loss: 1.1608763933181763, test_loss 1.2103081941604614
2023-11-14 02:04:15,319:INFO: Loading text inputs...
2023-11-14 02:04:15,321:INFO: Training
2023-11-14 02:04:15,528:INFO: iter 0, loss: 4.337672233581543, test_loss nan
2023-11-14 09:51:50,229:INFO: Loading text inputs...
2023-11-14 09:51:50,231:INFO: Training
2023-11-14 09:51:50,441:INFO: iter 0, loss: 4.334412574768066, test_loss nan
2023-11-14 09:54:24,589:INFO: Loading text inputs...
2023-11-14 09:54:24,648:INFO: Training
2023-11-14 09:54:25,465:INFO: iter 0, loss: 4.337531566619873, test_loss 2.5284533500671387
2023-11-14 09:55:42,406:INFO: iter 500, loss: 1.5835615396499634, test_loss 1.5804240703582764
2023-11-14 09:56:59,033:INFO: iter 1000, loss: 1.4816399812698364, test_loss 1.519598364830017
2023-11-14 09:58:15,622:INFO: iter 1500, loss: 1.4269752502441406, test_loss 1.4936139583587646
2023-11-14 09:59:31,848:INFO: iter 2000, loss: 1.4079878330230713, test_loss 1.4723950624465942
2023-11-14 10:00:46,565:INFO: iter 2500, loss: 1.3842322826385498, test_loss 1.4555000066757202
2023-11-14 10:02:02,458:INFO: iter 3000, loss: 1.3654203414916992, test_loss 1.4552072286605835
2023-11-14 10:03:17,656:INFO: iter 3500, loss: 1.3614894151687622, test_loss 1.4457156658172607
2023-11-14 10:04:35,519:INFO: iter 4000, loss: 1.3628093004226685, test_loss 1.4497921466827393
